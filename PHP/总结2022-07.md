------------------------------------- PHP基础 -------------------------------------

数据类型：int float bool string    object callable array    resource null
false: '' 0 0.0 [] '0' null
进制表达前缀：0x 0 0b
整数溢出转化为float，5/3结果为1.666...
浮点数转整数，向下取整
string是由字节组成的数组加上一个整数指明缓冲区的长度。可以把string当做字符组成的array，字符串会按照脚本文件的编码方式编码，strlen mb_strlen，字符串类型既是字符串也是byte，二进制字符串
数组的key是int或者string，值可以是任意类型，如果数组定义中有多个相同的键，后面会覆盖前面的值，如果没指定键名，则为最大整数键名加一

array是列表、散列表（哈希表）、队列、栈、集合、树形结构、多维数组，底层实现是散列表(HashTable结构体)。HashTable包含一些计数器和Bucket指针，Bucket包含Key,Key的哈希值和Zval，映射函数将key与value建立映射关系，可以根据key的哈希值与Bucket数组大小取模得到。哈希碰撞是指不同的key可能计算得到相同的哈希值，这时Bucket里面的zval里面的联合体里有一个指针会串成链表，查找时遍历链表比较key。

函数引用传递参数和返回引用，定义和使用都要带上&符号
引用是用不同的名字访问同一个变量的内容，引用不是指针，不是内存地址，而是符号表别名，可以看作是linux的硬连接
unset一个引用只是断开变量名与内容的联系，参考linux的硬连接

password_hash password_verify

php的变量保存在zval结构体中，一个zval包含变量的类型和zend_value结构体（用于存放变量实际的value）、is_ref（区分普通变量和引用变量）、refcount（指向这个变量容器的变量个数）
变量内存管理通过引用计数（变量赋值、传递时并不会直接硬拷贝）+写时复制
并不是所有的php变量都会用到refcount，标量：true/false/double/long/null是硬拷贝不需要，interned string（可以理解为预定义字符串）也不需要
|     type       | refcounted |
+----------------+------------+
|simple types    |            |
|string          |      Y     |
|interned string |            |
|array           |      Y     |
|immutable array |            |
|object          |      Y     |
|resource        |      Y     |
|reference       |      Y     |
写时复制：当一个变量试图更改value时候，会复制value并更改，断开旧的指向（针对string、array）。
变量回收：主动销毁（unset）、自动销毁（gc）
目前垃圾只会出现在array、object两种类型中，所以只会针对这两种情况作特殊处理：当销毁一个变量时，如果发现减掉refcount后仍然大于0，且类型是IS_ARRAY、IS_OBJECT则将此value放入gc可能垃圾双向链表中，等这个缓冲buffer（zend_value的zend_refcounted_h结构体）达到一定数量后启动检查程序将所有变量检查一遍，如果确定是垃圾则销毁释放（深度优先遍历，把成员value的refcount减1，如果refcount为0，则清除）灰白黑。

xdebug_debug_zval('变量名')

php三大组成部分：
sapi是php的接入层，将用户的输入引导至php脚本，包含cli、php-fpm。
zend引擎，编译器（将php代码编译成可执行的opcodes），执行器（执行opcodes）
扩展

php不像go语言一样实现了http网络库，而是实现FastCGI协议，通过与web服务器配合来实现对http请求的处理。
fpm的实现就是创建一个master进程，在master进程中创建并监听socket，然后fork出多个子进程，这些子进程各自accept请求，子进程的处理非常简单，它在启动后阻塞在accept上，有请求到达后开始读取请求数据，读取完成后开始处理然后再返回，在这期间是不会接收其它请求的，也就是说fpm的子进程同时只能响应一个请求。
fpm可以同时监听多个端口，每个端口对应一个worker pool。
static: 这种方式比较简单，在启动时master按照pm.max_children配置fork出相应数量的worker进程，即worker进程数是固定不变的
dynamic: 动态进程管理，首先在fpm启动时按照pm.start_servers初始化一定数量的worker，运行期间如果master发现空闲worker数低于pm.min_spare_servers配置数(表示请求比较多，worker处理不过来了)则会fork worker进程，但总的worker数不能超过pm.max_children，如果master发现空闲worker数超过了pm.max_spare_servers(表示闲着的worker太多了)则会杀掉一些worker，避免占用过多资源，master通过这4个值来控制worker数

TS指Thread Safety，即线程安全，针对多线程
NTS 非线程安全，php-fpm是多进程单线程，因此适用

命名空间：解决类、函数、常量、接口名字冲突。
类的自动加载：spl_autoload_register，可以支持任意数量的加载器，直到类成功注册为止，里面还是用的是require。常用框架比如yii2（有一套自己的autoload）也是借用composer+PSR规范实现框架外部类的自动加载，通过引入/vendor/autoload.php
composer是php包管理器，也是自动加载的关键，它实现了类与文件的映射关系，并且使用spl_autoload_register在需要时载入内存。
psr4：命名空间必须对应一个目录，类名必须与php文件名相同，大小写敏感

获取客户端真实IP：HTTP_X_ORIGINAL_FORWARDED_FOR HTTP_X_FORWARDED_FOR HTTP_CLIENT_IP REMOTE_ADDR
服务器真实IP：SERVER_ADDR

重定向：header函数（location） + die
BOM头是一串隐藏的字符,用于让记事本等编辑器识别这个文件是否以UTF-8编码，PHP不能识别，会把BOM作为文件开头正文的一部分
if (substr($t, 0, 3) == '\xef\xbb\xbf') {
	$t = substr($t, 3);
}

PHP魔术方法：
__construct() __destruct() __set() __get() __isset() __isget() __sleep() __wakeup() __clone()

YII2 优点：结构清晰，组件齐全，能快速开发项目，特点：配置强大，自定义修改请求、响应、日志等，yii队列也很好用。依赖注入（Denpdency Injection, DI）和服务定位器（Service Locator）两种模式。

PHP7 性能提升的原因：程序运作时搬动的内存位数，存储变量的结构体变小、字符串结构体的改变、数组结构的改变

------------------------------------- 理论原理 -------------------------------------
BASE64编码
1 将待转换的字符串每三个字节分为一组，每个字节占8bit，那么共有24个二进制位。
2 将上面的24个二进制位每6个一组，共分为4组。
3 在每组前面添加两个0，每组由6个变为8个二进制位，总共32个二进制位，即四个字节。
4 根据Base64编码对照表（A-Z a-z 0-9 + /）获得对应的值，缺失的用=补上。

REDIS
redis是单线程的nosql（非关系型数据库）。
字符串、哈希、列表、集合、有序集合、发布订阅、GEO
字符串：计数器、key-value缓存数据、加锁解锁、数据库缓存、缓存session
哈希：hget hset 存储对象、缓存数据库查询结果、购物车
列表：按照插入顺序排序的列表 lpush lpop rpop rpush lrange 用作消息队列、api限流
集合：内部的键值对是无序的、唯一的 sadd smembers sismember spop srem 缓存日活记录，好友、关注、粉丝，数据全局去重，交集、并集、差集
有序集合 zadd zrem zrange zcard zrank 排名，延迟队列

发布/订阅：publish subscribe，Redis无法对消息持久化存储，没有提供消息传输保障
事务：watch multi exec，watch是一个乐观锁。入队期间错误会拒绝执行，执行期间会执行正确的指令，忽略错误的指令，即没有回滚功能。

过期键删除策略：定时删除（创建大量定时器，耗费CPU）、惰性删除（耗费内存）、定期删除（需要制定删除策略）。redis采用LRU（Least Recent Used，淘汰掉最不经常使用的，基于hashmap的双向链表数据结构）
RDB持久化：生成的RDB文件是经过压缩的二进制文件。SAVE BGSAVE（执行时客户端发送的SAVE BGSAVE不会执行，bgrewriteaof在bgsave执行完后执行），SAVE命令由服务器进程执行保存工作，因此会阻塞服务器，BGSAVE由子进程执行保存工作，不会阻塞。因此可以用BGSAVE自动保存：save 600 1，600秒修改一次就保存。
AOF持久化：只追加的方式，保存执行的写命令，AOF文件重写（数据相同，体积更小，bgrewriteaof），appendfsync：aways everysec no

`缓存穿透`，数据库没有的数据，缓存里自然没有。可以约定在一定时间内对返回为空的 Key 值依然进行缓存，接口层增加校验，布隆过滤器（用来判断某个Key是否一定不存在或者可能存在于容器当中，通过多个hash函数计算多个hash值，并将对应位置的值置为1，在空间和时间方面都具备巨大优势）
`缓存击穿`，有多个针对数据库存在但不在缓存中的数据的请求同时发送过来。加锁，设置热点数据永远不过期
`缓存雪崩`，大批不同的数据在短时间内一起失效，导致了这些数据的请求都击穿了缓存到达数据源。随机过期时间，设置热点数据永远不过期
`缓存污染`，双写一致性。指缓存中的数据与真实数据源中的数据不一致的现象。读数据时，先读缓存，缓存没有的话，再读数据源，然后将数据放入缓存，再响应请求。写数据时，先写数据源，然后失效（而不是更新）掉缓存。
发生时：限流、降级
`并发竞争`，分布式事务，分布式锁 zookeeper

Redis分布式锁：加锁$redis->set($key, 1, 'NX', 'EX', $expire) 解锁 键过期或del
api限流: 使用列表lrange，rpush存入时间，lpop弹出超时 事务的watch multi
消息队列：rpush生产消息，lpop消费消息。

Redis是基于内存采用单进程单线程的KV数据库，C语言编写。绝大部分操作都是在内存中操作，速度很快。并且它的数据结构是专门进行设计的。
避免了上下文切换和竞争条件（加锁解锁）

redis集群：主从，哨兵，cluster
主从：主服务器写，从服务器读，主从同步（PSYNC两种模式 1 完整同步，初次复制，RDB。2 增量同步，断线后复制的情况）
哨兵：Sentinel，是redis高可用的解决方案，由一个或多个sentinel组成sentinel系统，可以监控任意多个主从服务器，当某个主服务器A下线时，会将其中一个从服务器B（优先级最高->复制偏移量最大）升级为主服务器,并向其它从服务器发送slaveof命令，当A重新上线时会降级为B的从服务器。sentinel服务器是特殊的redis服务器，不使用数据库，当一个主服务器下线时，选举一个领头sentinel（选举规则：先到先得，超半数胜出），由这个领头sentinel对下线服务器进行故障转移处理。
cluster：是redis分布式的解决方案。一个redis集群由多个节点组成，一个节点就是一个redis服务器。每个节点都会使用clusterNode数据结构来记录自己和其它节点的状态。给每个节点分配槽（分片），计算键属于哪个槽（将key带入算法得到一个0到多少范围内的整数，类似hash值取模的算法）。节点分为主节点和从节点。可以进行重新分片。复制与故障转移机制与主从和sentinel类似。

redis慢查询日志：记录执行时间超过指定时间的日志。

HashMap的读写时间复杂度都是O(1)

redis线程模型：采用 IO 多路复用机制同时监听多个 Socket，根据 Socket 上的事件来选择对应的事件处理器进行处理。 IO 多路复用程序会监听多个 Socket，会将 Socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。

一致性hash：hash取模，当数量变化时会对应不上。将服务器使用IP地址或服务器名哈希后,对2^32取模，形成一个Hash环，再将数据key使用相同的函数哈希取模，沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器，对于节点的增减都只需重定位环空间中的一小部分数据。数据倾斜：增加虚拟节点。

MYSQL
mysql服务器逻辑架构：客户端->连接处理->查询缓存（内存中，退出历史舞台）  ___>  存储引擎（索引）
				|->解析器->优化器		            >
并发控制：共享锁（读锁）、排它锁（写锁）,获取锁、检查是否解锁、释放锁都会耗费资源。锁策略：在锁的开销和数据安全性之间的平衡。锁粒度：表锁（MySQL服务器层）和行锁（Innodb层，并发处理最好，开销最大）
读锁：多个事务可以对同一个数据添加多个读锁，数据被加上读锁后就不能再被加上写锁，所以其他事务不能对该数据进行写入，但仍然可以读取。
写锁：如果数据有加写锁，就只有持有写锁的事务才能对数据进行写入操作，数据加持着写锁时，其他事务不能写入数据，也不能施加读锁。
范围锁: 对于某个范围直接加排他锁，在这个范围内的数据不能被写入。
事务：ACID 原子性（一个事务中所有操作全部成功，全部失败）一致性（数据库总是从一个一致性的状态转换到另一个一致性的状态）隔离性（一个事务执行过程中不会对另一个事务产生影响）持久性（事务执行完后会写入磁盘，永久保存）
事务隔离级别：Read Uncommitted 读未提交（脏读）Read Committed 读已提交，写锁会一直持续到事务结束，但加的读锁在查询操作完成后就马上会释放。（不可重复读，事务A和B，A 多次读取同一数据，B 在A多次读取的过程中对数据作了修改并提交，导致A多次读取同一数据时，结果不一致）Repeatable Read 可重复读（innodb默认级别，通过行级锁+MVCC实现。幻读，A在读取范围数据时，B插入了一行，导致A多读了一行，多次读取记录数不同。innodb的mvcc处理了只读事务的幻读），对事务所涉及的数据加读锁和写锁，且一直持有至事务结束，但不再加范围锁。Serializable 串行化（对所有读取的行加锁，避免幻读，性能低）

嵌套事务：mysql没有明确的嵌套事务，START TRANSACTION;SQL1;START TRANSACTION;SQL2;在遇到START TRANSACTION时，前面的事务会被强制commit，可以通过SAVEPOINT和ROLLBACK TO实现类似功能，START TRANSACTION;SQL1;SAVEPOINT P1;SQL2;ROLLBACK TO P1;COMMIT; 这样SQL1会成功，SQL2会失败

死锁：innodb解决方式：检测到死锁的循环依赖后，将有最少行级排它锁的事务回滚，稍后重新执行该事务即可。
自动提交：autocommit，默认，每个sql被当做一个事务执行提交操作。
隐式锁：Innodb采用两阶段锁协议，事务执行时，随时都可能上锁，在commit或rollback后才会释放所有的锁。
显示锁：select ... lock in share mode (读锁)   select ... for update (写锁，处理超售的方法之一)
表级锁：一次性给sql涉及到的所有表加锁，因此不会死锁。
避免死锁：区分度高的列放到组合索引前面、将大事务拆成多个小事务来处理、在并发比较高的系统中，尽量不要显式加锁、减少范围查找、减少连接的表、将复杂SQL分解为多个简单的SQL


MVCC Multiversion Concurrency Control 多版本并发控制 在读取不加锁的情况下实现行级锁的效果，实现非阻塞读，只有写写之间相互阻塞。在Read Committed 和 Repeatable Read两个隔离级别下工作。
Innodb中每一行多了几个字段：DB_TRX_ID(当前事务的ID，自动递增) DB_ROLL_PT（指向undo log记录，通过这个指针获得之前版本的数据） DB_RAW_ID（） deleted_flag（事务执行时置位true，commit之后才真正删除）
Read View一致性视图：RC 在事务中每一个select操作前生成 RR 在第一个select操作前生成。InnoDB为每一个事务构造了一个数组m_ids用于保存一致性视图生成瞬间当前所有活跃事务(开始但未提交事务)的ID，只有当前事务修改的未commit版本和所有已提交事务版本允许被访问。
UPDATE操作都是读取当前读(current read)数据进行更新的。

Undo Log: 实现事务的原子性、实现多版本并发控制

Redo Log：如果每次修改都操作磁盘，IO成本和查找成本都很高。因此采用WAL（Write Ahead Logging）先写日志，再写磁盘。日志文件就叫做redo log（物理日志，固定大小，循环写，记录某个数据页做了什么改动），更新内存，在适当的时候从内存中更新到磁盘。
Redo Log innodb特有，保存了之前提交的记录,可以保证数据的安全性，crash-safe，innodb_flush_log_at_trx_commit 这个参数设置成 1，每次事务持久化

Bin Log: mysql服务器层，逻辑日志，归档日志,二进制形式记录，没有 crash-safe 能力。两种模式：statement：记录sql，row：记录修改前和修改后的行内容。sync_binlog 这个参数设置成 1 。主从复制、数据恢复

取ID=2的行->数据页在内存中（不在就从磁盘中读取）->内存中更新数据->写入redo-log prepare（redolog buffer）->写入bin log->更新redo log commit状态（日志写入磁盘），MySQL 使用两阶段（2PC）提交主要解决 binlog 和 redo log 的数据一致性的问题。

InnoDB 是另一个公司以插件形式引入 MySQL 的

性能优化：表结构优化、索引优化、查询优化、应用层优化（实现方式、redis缓存、mongdb分担存储）

服务器性能剖析
用explain分析sql:
type，type主要取值及其表示sql的好坏程度（由好到差排序）：system(const的特例，表中只有一行记录)>const(唯一索引或者主键索引中使用等值查询)>eq_ref(唯一索引或者主键索引)>ref(非唯一索引或者主键索引精确匹配)>range(使用索引来检索给定范围)>index(遍历索引树，内存)>ALL(遍历表，磁盘)。保证range，最好到ref。
key，实际被使用的索引列。
rows, 扫描的行数
Extra，使用优先级 空>Using index>Using Where>Using filesort（九死一生）>Using temporary（十死无生）。

范式：定义表和字段的一些规范。项目中通常混用范式和反范式
选择优化的数据类型（尽量小、尽量简单、需要索引的列避免NULL，改为NOT NULL），DECIMAL支持精确计算，把数据按照最小关系表的形式进行存储
汇总表、缓存表、slot计数器表


索引 索引是在存储引擎层实现而不是mysql服务器层。
B-Tree索引（层级更少，所有数据保存在叶子节点，顺序存储，有序链表，天然支持排序和范围查找，索引列的顺序非常重要：最左法则）
哈希索引：只有精确匹配索引所有列的查询才有效，innodb有一个自适应哈希索引的功能，当某些索引使用非常频繁，会基于B-tree索引之上再创建一个哈希索引。
全文索引：针对单词，不能匹配单词中的字母。mysql5.7后支持innodb的中文全文索引，只有字段的数据类型为 char、varchar、text 及其系列才可以建全文索引，fulltext key  使用 match 和 against（IN BOOLEAN MODE） 关键字，将ft_min_word_len 改为1，like + %在文本比较少时是合适的
索引三大优点：
1 大大减少服务器查询时扫描的数据量
2 避免排序和临时表
3 将随机I/O变为顺序I/O
三星索引：索引包含需要查找的全部记录、索引中的数据顺序和查找的排序顺序一致、索引的列包含查询的全部列
聚簇索引（innodb）：索引和数据放在一起，主键->唯一非空列->隐式定义主键。一个表只能有一个聚簇索引
二次索引：索引和数据分开。
前缀索引：创建前缀索引节省空间，但是会增加查询的扫描行数（回表精确查询），并且加了之后不能使用覆盖索引。key (name(6))   distinct/all 接近 name(len)/all 对应：将整个字符串作为索引结构
多列索引、单列索引
选择合适的索引列顺序，上小下大的树形结构是最合理的。
覆盖索引：一个索引包含所有需要查询的字段的值，只需要扫描索引而无需回表。mysql只能使用b-tree索引做覆盖索引。explain:Extra:Using index
延迟关联：将连表查询改为子查询，充分使用索引
索引排序：索引列顺序和order by的顺序完全一致，连表时order by 第一张表时才生效 explain: type:Using index
重复索引：同一列多次定义相同索引类型的索引
冗余索引：多列索引的情况
独立的列，避免多个范围查询，将范围查询改成精确查询，优化排序

查询优化（减少子任务的个数、单个子任务执行次数、单次执行时间，也就是说减少扫描行数和返回列数）
优化where条件、排序优化、一个复杂的查询、多个简单的查询（将关联放到应用程序中）、切分查询（分页处理）、子查询(创建临时表，用于替换关联查询，大分页）
count(列不包含null) union all 
水平扩展  IO 成本

InnoDB Myisam比较
事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。
并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。
外键：InnoDB 支持外键。
备份：InnoDB 支持在线热备份。
崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。

常用 MySQL 函数：数学函数、时间函数、字符串函数、聚合函数
分表数量级：MySQL 单表容量在500万左右，性能处于最佳状态


MEMCACHE
memcache支持简单数据类型，不支持数据持久存储，Redis在很多方面具备数据库的特征，或者说就是一个数据库系统，而Memcached只是简单的K/V缓存。redis支持单核，memcache支持多核


LINUX
常用指令：cd、ls -al、mkdir、rm -rf、cat、tail -10、cp、mv、tar、zip、find、ps -ef|grep、pwd、chmod、chown、ifconfig、ln、service、at、crontab、top、free、iostat、nestat、yum、df -hl、touch

MONGODB
Bson(Json的二进制形式)结构存储，占用更多硬盘空间，更易于遍历，支持二进制数据。MongoDB中的文档可以由任意数目的键和值组成，每个文档必须有一个唯一标识符_id。不要求每个文档有相同的字段，也不要求同名字段有相同类型的值
动态数据库，数据库->集合->文档->字段
支持排序、分页
固定集合：自然顺序与文档插入顺序一致，大小固定，环形写入
$gt $lt $gte $lte $ne $in $nin $exists(键名是否存在)
数组：$slice $size
可以使用JavaScript指定额外的查询表达式
索引会提高查询速度，但会降低插入和删除速度。强制使用索引，使用explain查看查询计划
GridFS存储大文件
全文本索引：只能为每个集合创建一个文本索引，但是可以指定多个字段
聚集框架：$group $limit $match $sort $unwind $project $skip $out $count $sum
MapReduce:

NGINX
Nginx是web服务器，也可以作为反向代理、负载均衡器和http缓存。
Nginx特点：单次请求更快、模块化高拓展性、高可靠性、低内存消耗、高并发单机支持10万以上的并发连接、热部署master 管理进程与 worker工作进程的分离设计，使得 Nginx 能够支持热部署、开源
Apache:是一个重量级、不支持高并发的Web服务器，应为它是多进程的模式，高并发会消耗大量内存。

Nginx的FastCGI模块提供了fastcgi_param指令(conf/fastcgi.conf)，其主要完成的工作是将Nginx中的变量翻译成PHP中能够理解的变量。
描述nginx与php运行原理：

当 nginx reload 的时候 master 进程ID是没有变化的，worker 进程ID是有变化的。而nginx restart 的时候 master，worker的进程ID都有变化。reload 时，旧的worker进程和新的worker进程是共存的，旧的worker进程在处理完请求后会被杀掉。而 restart时，不会存在新旧共存的情况（master，worker 都是）。如果有请求未完成时，旧的master、worker 会有一段时间处理请求（超时时间）。然后被杀掉，创建新的master、worker 进程。所以 restart 的时候nginx 会有卡顿的现象。
// 重启php-fpm
php-fpm.conf 配置 process_control_timeout=5 master进程留给worker进程结束自己的时间
`kill -USR2 'cat /usr/local/php/var/run/php-fpm.pid'`

负载均衡策略：
轮询，服务器接收请求的比例是 1:1， 如果后端服务器down掉，能自动剔除
upstream web_servers {
   server localhost:8081;
   server localhost:8082;
}
权重，指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均
upstream test {
    server localhost:8081 weight=1;
    server localhost:8082 weight=3;
    server localhost:8083 weight=4 backup;
}
ip_hash，每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，解决session等问题
upstream test {
    ip_hash;
    server localhost:8080;
    server localhost:8081;
}
fair（第三方），按后端服务器的响应时间来分配请求，响应时间短的优先分配
upstream backend {
    fair;
    server localhost:8080;
    server localhost:8081;
}
url_hash(第三方)，按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。
upstream backend {
    hash $request_uri;
    hash_method crc32;
    server localhost:8080;
    server localhost:8081;
}




------------------------------------- 分布式高并发架构 -------------------------------------
单体系统的缺陷：缺乏隔离、自治、技术异构能力，没法做到单独停止、更新、升级，需要制定专门的停机更新计划。
SOA，Service-Oriented Architecture，面向服务架构，松散耦合、注册、发现、治理，隔离、编排
微服务架构（Microservices）

微服务是一种通过多个小型服务组合来构建单个应用的架构风格，这些服务围绕业务能力而非特定的技术标准来构建。各个服务可以采用不同的编程语言，不同的数据存储技术，运行在不同的进程之中。服务采取轻量级的通信机制和自动化的部署机制实现通信与运维。
边车代理模式：由系统自动在服务容器（通常是指 Kubernetes 的 Pod）中注入一个通信代理服务器，这个代理除了实现正常的服务间通信外，还接收来自控制器的指令（熔断、认证、度量、监控、负载均衡等）
RESTful 资源表征状态转移，面向资源来抽象问题。降低的服务接口的学习成本，资源天然具有集合与层次结构(GET /users/icyfenix/cart/2),绑定于 HTTP 协议，使用HTTP的方法和状态码。

本地事务：单个应用使用单个数据源：ACID，超卖用lock in share mode
全局事务：单个事务使用多个数据源：XA，二阶段提交（2 Phase Commit，2PC，准备阶段，提交阶段，存在单点问题、性能问题、一致性风险）
共享事务：多个不同的服务共用同一个数据源
分布式事务：多个服务同时访问多个数据源，CAP，可靠消息队列，靠着持续重试来保证可靠性

CAP 定理（Consistency、Availability、Partition Tolerance Theorem）
一致性 代表数据在任何时刻、任何分布式节点中所看到的都是符合预期的。
可用性 代表系统不间断地提供服务的能力，理解可用性要先理解与其密切相关两个指标：可靠性（Reliability）和可维护性（Serviceability）。
分区容忍性 代表分布式环境中部分节点因网络原因而彼此失联后，即与其他节点形成“网络分区”时，系统仍能正确地提供服务的能力。

如果放弃分区容忍性（CA without P），意味着我们将假设节点之间通信永远是可靠的。永远可靠的通信在分布式系统中必定不成立的。
如果放弃可用性（CP without A），意味着我们将假设一旦网络发生分区，节点之间的信息同步时间可以无限制地延长，可以通过 2PC/3PC 等手段同时获得分区容忍性和一致性。银行、证券这些涉及金钱交易的服务，宁可中断也不能出错。
如果放弃一致性（AP without C），意味着我们将假设一旦发生分区，节点之间所提供的数据可能不一致。选择放弃一致性的 AP 系统目前是设计分布式系统的主流选择。大多数 NoSQL 库（redis等）和支持分布式的缓存框架。

BASE可靠事件队列：用户账号扣款、商家账号收款、库存商品例子，消息队列服务器将在每次轮询的时候持续地向未响应的服务重复发送消息，所有被消息服务器发送的消息都必须具备幂等性，通常的设计是让消息带上一个唯一的事务 ID，以保证一个事务中的出库、收款动作会且只会被处理一次。最大努力交付，不支持回滚，缺乏隔离性。

TCC事务：Try-Confirm-Cancel
Try：尝试执行阶段，完成所有业务可执行性的检查（保障一致性），冻结并暂存全部需用到的业务资源（保障隔离性）。
Confirm：确认执行阶段，不进行任何业务检查，直接使用 Try 阶段准备的资源来完成业务处理，解冻资源。Confirm 阶段可能会重复执行，因此本阶段所执行的操作需要具备幂等性。
Cancel：取消执行阶段，解冻 Try 阶段预留的业务资源。Cancel 阶段可能会重复执行，也需要满足幂等性。
TCC 其实有点类似 2PC 的准备阶段和提交阶段，但 TCC 是位于用户代码层面，而不是在基础设施层面。TCC 事务具有较强的隔离性，避免了“超售”的问题。
局限：业务侵入性很强，如果用户、商家的账号余额由银行管理，也就无法完成冻结款项、解冻、扣减这样的操作。

SAGA事务：大事务拆分若干个原子事务，为每一个子事务设计对应的补偿动作，Ti与 Ci都具备幂等性。Ti与 Ci满足交换律（Commutative），即先执行 Ti还是先执行 Ci，其效果都是一样的。Ci必须能成功提交。如果 T1到 Tn均成功提交，那事务顺利完成，否则采用正向恢复（最大努力交付）或反向恢复（补偿机制）

DNS：客户端先检查本地的 DNS 缓存，DNS 是以存活时间（Time to Live，TTL）来衡量缓存的有效情况的，本地 DNS 收到查询请求后，会按照“是否有www.icyfenix.com.cn的权威服务器”→“是否有icyfenix.com.cn的权威服务器”→“是否有com.cn的权威服务器”→“是否有cn的权威服务器”的顺序，依次查询自己的地址记录，如果都没有查询到，就会一直找到最后点号代表的根域名服务器为止。它将会得到“cn的权威服务器”的地址记录，然后通过“cn的权威服务器”，得到“com.cn的权威服务器”的地址记录，以此类推，最后找到能够解释www.icyfenix.com.cn的权威服务器地址。通过“www.icyfenix.com.cn的权威服务器”，查询www.icyfenix.com.cn的地址记录。
<link rel="dns-prefetch" href="//domain.not-icyfenx.cn">前端对域名预加载。

CDN 路由解析：
1 架设好“icyfenix.cn”的服务器后，将服务器的 IP 地址在你的 CDN 服务商上注册为“源站”，注册后你会得到一个 CNAME，即本例中的“icyfenix.cn.cdn.dnsv1.com.”。
2 将得到的 CNAME 在你购买域名的 DNS 服务商上注册为一条 CNAME 记录。
3 当第一位用户来访你的站点时，将首先发生一次未命中缓存的 DNS 查询，域名服务商解析出 CNAME 后，返回给本地 DNS，至此之后链路解析的主导权就开始由内容分发网络的调度服务接管了。
4 本地 DNS 查询 CNAME 时，由于能解析该 CNAME 的权威服务器只有 CDN 服务商所架设的权威 DNS，这个 DNS 服务将根据一定的均衡策略和参数，如拓扑结构、容量、时延等，在全国各地能提供服务的 CDN 缓存节点中挑选一个最适合的，将它的 IP 代替源站的 IP 地址，返回给本地 DNS。
5 浏览器从本地 DNS 拿到 IP 地址，将该 IP 当作源站服务器来进行访问。

CDN 获取源站资源的过程被称为“内容分发”：
主动分发（Push）：分发由源站主动发起，将内容从源站或者其他资源库推送到用户边缘的各个 CDN 缓存节点上。
被动回源（Pull）：当某个资源首次被用户请求的时候，CDN 缓存节点发现自己没有该资源，就会实时从源站中获取，这时资源的响应时间可粗略认为是资源从源站到 CDN 缓存节点的时间，再加上资源从 CDN 发送到用户的时间之和。

四层负载均衡的优势是性能高，七层负载均衡的优势是功能强。

引入缓存的理由：
为缓解 CPU 压力而做缓存：把方法运行结果存储起来、把原本要实时计算的内容提前算好等
缓解 I/O 压力而做缓存：譬如把原本对网络、磁盘等较慢介质的读写访问变为对内存等较快介质的访问，将原本对单点部件（如数据库）的读写访问变为到可扩缩部件（如缓存中间件）的访问等。
是典型以空间换时间来提升性能的手段。

OAuth 
授权码模式（Authorization Code）
隐式授权模式（Implicit）
密码模式（Resource Owner Password Credentials）
客户端模式（Client Credentials）
授权码模式开放授权，允许用户向第三方应用提供某一网站的私密数据，而不用将用户的账号密码提供给第三方。以令牌（Token）代替用户密码作为授权的凭证。有了令牌之后，哪怕令牌被泄漏，也不会导致密码的泄漏；令牌上可以设定访问资源的范围以及时效性；每个应用都持有独立的令牌，哪个失效都不会波及其他。
授权码模式：
1 第三方应用先要到授权服务器上进行注册，所谓注册，是指向认证服务器提供一个域名地址，然后从授权服务器中获取 ClientID 和 ClientSecret，
2 第三方应用将资源所有者（用户）导向授权服务器的授权页面，并向授权服务器提供 ClientID 及用户同意授权后的回调 URI
3 如果用户同意授权，授权服务器将转向第三方应用在第 1 步调用中提供的回调 URI，并附带上一个授权码和获取令牌的地址作为参数
4 第三方应用通过回调地址收到授权码，然后将授权码与自己的 ClientSecret 一起作为参数，通过服务器向授权服务器提供的获取令牌的服务地址发起请求，换取令牌。
5 授权服务器核对授权码和 ClientSecret，确认无误后，向第三方应用授予令牌。
6 资源服务器根据访问令牌所允许的权限，向第三方应用提供资源。
访问令牌的时效性一般设计的比较短，因为很难（需要付出较大代价）有其他方式让它失效。

JWT是一种广泛使用的令牌格式，JSON结构，可用于单客户端对应多服务器的场景。无状态（难以统计实时在线人数）,令牌难以主动失效。

客户端如何加密都不能代替 HTTPS。

摘要也称之为数字摘要（Digital Digest）或数字指纹（Digital Fingerprint）。
加密与摘要的本质区别在于加密是可逆的，逆过程就是解密。
对称加密：加密和解密使用相同的密钥。
非对称加密：从根本上解决了密钥分发的难题，它将密钥分成公钥和私钥。
TLS 1.2：无法窃听（加密传输）、无法篡改（一旦篡改通信算法会立刻发现）、无法冒充（证书验证身份）

状态转移：以同步为代表的数据复制方法
让分布式系统内部暂时容忍存在不同的状态，但最终能够保证大多数节点的状态达成一致，让分布式系统在外部看来始终表现出整体一致的结果。

paxos是一种协商共识算法
Paxos 算法将分布式系统中的节点分为三类：
提案节点：称为 Proposer，提出对某个值进行设置操作的节点，设置值这个行为就被称之为提案（Proposal），值一旦设置成功，就是不会丢失也不可变的
决策节点：称为 Acceptor，是应答提案的节点，决定该提案是否可被投票、是否可被批准。
记录节点：被称为 Learner，不参与提案，也不参与决策，只是单纯地从提案、决策节点中学习已经达成共识的提案
示例 S1、S2、S3、S4、S5节点，引入随机超时时间来避免活锁的产生。

Multi Paxos 即Raft算法 对 Basic Paxos 的核心改进是增加了“选主”的过程，这时候的二元组(id, value)已经变成了三元组(id, i, value)，这是因为需要给主节点增加一个“任期编号”。
主节点将 X 写入自己的变更日志，但先不提交，接着把变更 X 的信息在下一次心跳包中广播给所有的从节点，并要求从节点回复确认收到的消息，从节点收到信息后，将操作写入自己的变更日志，然后给主节点发送确认签收的消息，主节点收到过半数的签收消息后，提交自己的变更、应答客户端并且给从节点广播可以提交的消息，从节点收到提交消息后提交自己的变更，数据在节点间的复制宣告完成。
通过随机超时来实现无活锁的选主过程，通过主节点来发起写操作，通过心跳来检测存活性，通过Quorum机制来保证一致性。

Gossip 协议：比特币网络中使用到了 Gossip 协议，用它来在各个分布式节点中互相同步区块头和区块体的信息
1 如果有某一项信息需要在整个网络中所有节点中传播，那从信息源开始，选择一个固定的传播周期（譬如 1 秒），随机选择它相连接的 k 个节点（称为 Fan-Out）来传播消息。
2 每一个节点收到消息后，如果这个消息是它之前没有收到过的，将在下一个周期内，选择除了发送消息给它的那个节点外的其他相邻 k 个节点发送相同的消息，直到最终网络中所有节点都收到了消息，尽管这个过程需要一定时间，但是理论上最终网络的所有节点都会拥有相同的消息。

服务发现注册中心：1 在分布式 K/V 存储框架上自己开发的服务发现，这类的代表是 ZooKeeper、Doozerd、Etcd 2 专门用于服务发现的框架和工具，这类的代表是 Eureka、Consul 和 Nacos2 
网关 = 路由器（基础职能） + 过滤器（可选职能）

流量控制
每秒事务数（Transactions per Second，TPS）每秒请求数（Hits per Second，HPS）每秒查询数（Queries per Second，QPS）
限流设计模式：滑动时间窗模式、漏桶模式、令牌桶模式。

RPC
客户端->请求数据序列化->网络->请求数据反序列化->服务器函数调用->响应数据序列化->网络->响应数据反序列化->服务器端

------------------------------------- 计算机网络 -------------------------------------

应用层 http https smpt ftp ssh telnet | ntp(网络时间同步) dhcp(动态配置IP地址) | dns
传输层 tcp udp
网络层 ip数据报
链路层 传输ip数据报组装成的帧，在两个相邻节点的链路上传输帧，mac地址
物理层 传输bit字节

upd的特点：无连接的，发送数据之前不需要建立连接，减少开销和发送数据之前的延时，支持一对一、一对多、多对一和多对多的交互通信，使用最大努力交付，不保证可靠交互，没有拥塞控制，网络出现的拥塞不会使源主机的发送速率降低，首部开销小，只有8个字节，比 TCP 的20个字节的首部要短
tcp的特点：有连接的，发送数据之前需要建立连接，数据发送完后需要释放连接，只支持一对一的通信，提供可靠交互（无差错、不丢失、不重复，并且按序到达），全双工通信，允许通信双方的应用进程在任何时候都能发送数据

tcp三次握手：服务器listen状态->客户端发送syn报文，syn_send状态->服务器接收报文，发送syn+ack报文，syn_recv状态->客户端接收报文，发送ack报文，established状态->服务器接收报文，established状态
为什么三次握手：双方确认自己与对方的发送与接收是正常的。

tcp四次挥手：客户端established，服务器端established->客户端发送fin报文，并停止发送数据，fin_wait1状态->服务器接收报文，发送ack报文，close_wait状态->客户端接收报文，fin_wait2状态->服务器也没有数据需要发送后，发送fin+ack报文，lask_ack状态->客户端接收报文，发送ack报文，time_wait状态,超时后进入closed状态->服务器接受报文，closed状态
为什么四次挥手：tcp的半关闭特性决定的，即连接的一端发送完数据之后，还能接受另一端的数据的能力。
TIME-WAIT是什么，为什么必须等待 2MLS:等待 2MLS 可以保证客户端最后一个报文段能够到达服务器。

建立套接字的步骤：创建socket，绑定socket到指定ip和端口，开始监听连接，接受客户端数据，关闭socket。

HTTP报文是纯文本字符串，不是二进制代码
|301|Moved Permanently|在请求的链接被移除时使用
|302|Found|在请求临时的链接使用
|400|Bad Request|告知客户端发送了错误请求
|403|Forbidden|请求被服务器拒绝
|404|Not Found|无法找到所请求的 URL
|413|Request entiry too large|请求实体过大
|500|Internal Server Error|服务器遇到错误
|502|Bad Gateway|代理或网关错误(无法连接到其父网关) php-fpm 没有可用的worker进程（worker进程不够用了）
|503|Service Unavailable|无法为请求提供服务
|504|Gateway Timeout|代理或网关超时(等待另一服务器响应超时) worker进程响应超时（php代码执行超时）

心跳机制：定时发送一个自定义的数据包，以确认双发是否保持连接。

Websocket:Websocket与HTTP(80)和HTTPS(443)使用相同的TCP端口。服务器可以随时主动给客户端下发数据。WebSocket 是独立的、建立在TCP上的协议。Websocket 通过 HTTP/1.1 协议的101状态码进行握手。

------------------------------------- 数据结构 -------------------------------------

数据组织的基本存储方式主要是利用数组和链表方式来实现的，包括很复杂的数据结构，如图、树，也都不外乎应用数组和链表来实现


XSS（cross site script） 在网站上注入恶意客户端代码（js脚本、链接、html实体），过滤输入请求，strip_tags、htmlspecialchars、htmlentities 
CSRF （cross site request forgery）攻击者诱导用户进入第三方网站，在第三方网站中向被攻击网站发送跨站请求，1 同源检测 2 token 将CSRF Token输出到页面中，请求时携带Token，服务器端验证token

重放攻击 时间戳+随机数(nonce)





------------------------------------- RabbitMQ -------------------------------------
消息系统允许软件、应用相互连接和扩展．这些应用可以相互链接起来组成一个更大的应用，消息系统通过将消息的发送和接收分离来实现应用程序的异步和解偶。
AMQP（高级消息队列协议）是一个网络协议。它支持符合要求的客户端应用（application）和消息中间件代理（messaging middleware broker）之间进行通信。
publisher->publish->exchange->router->queue->consumes->consumer

发布者（publisher）消息属性 消息确认（确认回执）当一个消息无法被成功路由时，消息或许会被返回给发布者并被丢弃。
队列、交换机和绑定统称为AMQP实体
交换机可以有两个状态：持久（durable）、暂存（transient）。持久化的交换机会在消息代理（broker）重启后依旧存在，而暂存的交换机则不会
消息的负载均衡是发生在消费者（consumer）之间的，而不是队列（queue）之间。
消息是没有超时这个概念的；当工作者与它断开连的时候，RabbitMQ会重新发送消息。

默认交换机（default exchange）实际上是直连型交换机，每个新建队列（queue）都会自动绑定到默认交换机上，绑定的路由键（routing key）名称与队列名称相同。
直连型交换机（direct exchange）是根据消息携带的路由键（routing key）将消息投递给对应队列的。
扇型交换机（funout exchange）将消息路由给绑定到它身上的所有队列，而不理会绑定的路由键。排行榜更新等全局事件、分发系统广播、群聊分发消息
主题交换机（topic exchanges）通过对消息的路由键和队列到交换机的绑定模式之间的匹配，将消息路由给一个或多个队列。分发/订阅模式。发送到主题交换机（topic exchange）的消息不可以携带随意什么样子的路由键（routing_key），它的路由键必须是一个由.分隔开的词语列表。
\* (星号) 用来表示一个单词.
\# (井号) 用来表示任意数量（零个或多个）单词。
头交换机（headers exchange）使用多个消息属性来代替路由键建立路由规则。通过判断消息头的值能否与指定的绑定相匹配来确立路由规则。可以视为直连交换机的另一种表现形式。x-match：any/all

队列（queue）存储着即将被应用消费掉的消息。队列在声明（declare）后才能被使用。声明一个队列是幂等的。
持久化队列（Durable queues）会被存储在磁盘上，当消息代理（broker）重启的时候，它依旧存在。
绑定（Binding）是交换机（exchange）将消息（message）路由给队列（queue）所需遵循的规则。

消费者 push/pull
消息确认：自动确认模式（消息代理（broker）将消息发送给应用后立即删除）/显式确认模式（消费者应用来选择什么时候发送确认回执）
如果一个消费者在尚未发送确认回执的情况下挂掉了，那AMQP代理会将消息重新投递给另一个消费者。
默认轮询的方式将消息发送给消费者。

如果没有绑定队列到交换器，消息将会丢失。但这个没有所谓，如果没有消费者监听，那么消息就会被忽略。

PHP使用RabbitMQ:
composer require php-amqplib/php-amqplib

RabbitMQ实现RPC：客户端将请求数据（json格式）发布到队列A，并且监听队列B。服务器监听队列A，接受请求数据并处理后，返回数据发布到队列B。客户端处理队列B数据。由于一个客户端可以对应多个服务器，需要correlation_id参数确认连接是否对应。

------------------------------------- Swoole -------------------------------------
协程：可以理解为用户态的线程，不需要操作系统参与，创建销毁和切换的成本非常低，没法利用多核cpu。


------------------------------------- 认证、鉴权 -------------------------------------
单点认证Single Sign On，简称就是SSO，实现方式：认证中心
我们可以部署一个专门用于处理登录请求的独立的Web服务,也称之为认证中心。
用户统一在认证中心进行登录，登录成功后，认证中心记录用户的登录状态，并将 Token 写入 Cookie。（注意这个 Cookie 是认证中心的，应用系统是访问不到的。）
应用系统检查当前请求有没有 Token，如果没有，说明用户在当前系统中尚未登录，那么就将页面跳转至认证中心。由于这个操作会将认证中心的 Cookie 自动带过去，因此，认证中心能够根据 Cookie 知道用户是否已经登录过了。
如果认证中心发现用户尚未登录，则返回登录页面，等待用户登录，如果发现用户已经登录过了，就不会让用户再次登录了，而是会跳转回目标 URL ，并在跳转前生成一个 Token，拼接在目标 URL 的后面，回传给目标应用系统。
应用系统拿到 Token 之后，还需要向认证中心确认下 Token 的合法性，防止用户伪造。确认无误后，应用系统记录用户的登录状态，并将 Token 写入 Cookie，然后给本次访问放行。（注意这个 Cookie 是当前应用系统的，其他应用系统是访问不到的。）当用户再次访问当前应用系统时，就会自动带上这个 Token，应用系统验证 Token 发现用户已登录，于是就不会有认证中心什么事了。

CI 持续集成（Continuous Integration）
可以帮助开发人员更加频繁地（有时甚至每天）将代码更改合并到共享分支或"主干"中。

CD 持续交付（Continuous Delivery）
在持续交付中，每个阶段（从代码更改的合并，到生产就绪型构建版本的交付）都涉及测试自动化和代码发布自动化。

CD 持续部署（Continuous Deployment）
持续部署可以自动将应用发布到生产环境。

持续集成和持续部署管道（CI/CD）是实施 DevOps 的一大重要成果。
DevOps将开发与部署紧密结合，提升效率。

curl -u username:password形式使用的是http authentication 中的basic形式，将testclient:testpass进行base64加密得到  dXNlcm5hbWU6c2VjcmV0  然后前面加上一个Basic和空格
Authorization: Basic dGVzdGNsaWVudDp0ZXN0cGFzcw==

ACL Access Control List 
ABAC Attribute-Based Access Control 
RBAC Role-Based Access Control rbac0 rbac1 rbac2

APISIX 是基于 NGINX + Lua, 即openresty 实现的

服务降级、熔断、限流
配置中心、监控中心、日志中心、持久化、缓存、队列
Lua 脚本语言，简单高效，可以调用c的库

oauth2


------------------------------------- Kafka -------------------------------------

点对点的消息系统 消息保留在队列中，一个或者多个消费者可以消耗队列中的消息，但是消息最多只能被一个消费者消费,最典型的例子就是订单处理系统
发布-订阅消息系统 消费者可以订阅一个或多个主题并使用该主题中的所有消息。Kafka 是一个分布式消息队列，具有高性能、持久化、多副本备份、横向扩展能力。生产者往队列里写消息，消费者从队列里取消息进行业务逻辑。一般在架构设计中起到解耦、削峰、异步处理的作用。
Kafka构建在ZooKeeper同步服务之上。ZooKeeper基于etcd。

Apache Kafka 的一个关键依赖是 Apache Zookeeper，它是一个分布式配置和同步服务。Zookeeper 是 Kafka 代理和消费者之间的协调接口。Kafka 服务器通过 Zookeeper 集群共享信息。Kafka 在 Zookeeper 中存储基本元数据，例如关于主题，代理，消费者偏移(队列读取器)等的信息。

由于所有关键信息存储在 Zookeeper 中，并且它通常在其整体上复制此数据，因此Kafka代理/ Zookeeper 的故障不会影响 Kafka 集群的状态。Kafka 将恢复状态，一旦 Zookeeper 重新启动。 这为Kafka带来了零停机时间。Kafka 代理之间的领导者选举也通过使用 Zookeeper 在领导者失败的情况下完成。

kafka 削峰填谷
消息：Record。Kafka 是消息引擎嘛，这里的消息就是指 Kafka 处理的主要对象。

主题：Topic。消息分类。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。

分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区。一个分区对应一个append log文件，可以负载均衡。

消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。

副本：Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。

生产者：Producer。向主题发布新消息的应用程序。

消费者：Consumer。从主题订阅新消息的应用程序。对于消费者，不是以单独的形式存在的，每一个消费者属于一个 consumer group，一个 group 包含多个 consumer。特别需要注意的是：订阅 Topic 是以一个消费组来订阅的，发送到 Topic 的消息，只会被订阅此 Topic 的每个 group 中的一个 consumer 消费。同一个消费组的两个消费者不会同时消费一个 partition。如果所有的 Consumer 都具有相同的 group，那么就像是一个点对点的消息系统；如果每个 consumer 都具有不同的 group，那么消息会广播给所有的消费者。
consumer 在和 broker 建立连接之后，主动去 pull(或者说 fetch )消息。
消费者位移：Consumer Offset。下一条消息的位移，表征消费者消费进度，每个消费者都有自己的消费者位移。

消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。

重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。

Kafka 的消息组织方式实际上是三级结构：主题 - 分区 - 消息。

比较常见的分区策略包括轮询（Round-robin）策略、随机策略（从实际表现来看，它要逊于轮询策略）和按消息键保序策略。
Kafka 允许为每条消息定义消息键，简称为 Key。这个 Key 的作用非常大，它可以是一个有着明确业务含义的字符串，比如客户代码、部门编号或是业务 ID 等；也可以用来表征消息元数据。
一旦消息被定义了 Key，那么你就可以保证同一个 Key 的所有消息都进入到相同的分区里面，由于每个分区下的消息处理都是有顺序的，故这个策略被称为按消息键保序策略。
Kafka 是不能保证全局消息顺序的，只能保证单个 Partition 下的顺序

主题分区数应当是消费者数的倍数

重平衡的触发条件主要有三个：
消费者组内成员发生变更，这个变更包括了增加和减少消费者。注意这里的减少有很大的可能是被动的，就是某个消费者崩溃退出了
主题的分区数发生变更，kafka目前只支持增加分区，当增加的时候就会触发重平衡
订阅的主题发生变化，当消费者组使用正则表达式订阅主题，而恰好又新建了对应的主题，就会触发重平衡
重平衡过程中，消费者无法从kafka消费消息，应当避免触发重平衡。

kafka利用分区进行负载均衡。

消费者位移用于消费者端的崩溃恢复。当 Consumer发生故障重启之后，就能够从 Kafka 中读取之前提交的位移值，然后从相应的位移处继续消费，从而避免整个消费过程重来一遍。
消费者位移也是一个普通的主题，第一个消费者程序启动的时候，Kafka 会自动创建这个主题。这位移主题中的消息，可以简单地理解为「某个消费者组在某个主题的某个分区的消费位移是多少」，也可以理解为一个键值对，其中的 Key 是 Group ID + Topic + Partition，Value 就是位移
它通过 Compact 策略，对于同一个 Key 的消息，只保留最新的一条。（如果你了解 Redis，这与 Redis 的 AOF 重写机制很相似）。

Kafka 的消费者可以手动提交位移，并且可以提交并非当前位置的位移，这样可以实现跳过或者重新消费消息。这主要是因为 Kafka 是一个基于日志结构的消息系统，而并非「队列」结构。
位移数据是消费者控制的。要注意的是，消费者只能控制位移，不能控制消息，消息对于消费者来说，永远都是只读的。
Earliest
把位移重设到当前最早位移处。

这里要注意，因为 Kafka 会删除较早的日志，因此，最早的位置不一定是 0。如果你想重新消费主题中现有的所有消息，可以使用这个策略。
Latest
把位移重设到当前最新位移处。

如果你想跳过所有的历史消息，从最新的消息开始消费，那么就是用这个策略。
Specified-Offset
把位移重设到一个指定的位移处。

因为 Consumer 能够同时消费多个分区的数据，所以位移的提交实际上是在分区粒度上进行的，即Consumer 需要为分配给它的每个分区提交各自的位移数据。
当消费配置enable.auto.commit=true的时候代表自动提交位移。
auto.commit.interval.ms默认值5秒，自动位移提交的动作是在 poll（）方法的逻辑里完成的。自动提交带来重复消费和消息丢失的问题。

kafka的诞生，是为了解决linkedin的数据管道问题。

kafak是日志文件追加的方式保存数据。

Kafka 的消息组织方式实际上是三级结构：主题 - 分区 - 消息。

一条消息从生产到消费一共要经过以下 3 个流程：

1）Producer 发送到 Broker
2）Broker 保存消息(持久化)
3）Consumer 消费消息

Consumer 端丢失数据主要体现在 Consumer 端要消费的消息不见了。

出现该情况的唯一原因就是：Consumer 没有正确消费消息，就把位移提交了，导致 Kafka 认为该消息已经被消费了，从而导致消息丢失。

常见的承诺有以下三种：

最多一次（at most once）：消息可能会丢失，但绝不会被重复发送。
至少一次（at least once）：消息不会丢失，但有可能被重复发送。
精确一次（exactly once）：消息不会丢失，也不会被重复发送。
目前，Kafka 默认提供的交付可靠性保障是第二种，即至少一次。

只能保证单分区、单会话上的幂等性。最好是在Consumer端实现幂等

Kafak的高吞吐和低延迟是怎么实现的：页缓存技术+磁盘顺序写
Kafka在写入消息时是直接写入页缓存，然后由操作系统决定什么时候把页缓存里的数据刷入磁盘文件中。这样一来，消息写入性能就变成了写内存，不是在写磁盘
通过追加文件末尾按照顺序的方式来写数据的话，其写入性能跟写内存的性能都相差无几的，Kafak就是采用顺序写的方案。
读取：0拷贝（Zero-Copy）技术。Kafka 从磁盘读数据的时候，会先看看内核空间的页缓存中是否有，如果有的话，直接通过网关发送出去。

Kafka如果开启幂等、事务等功能，性能也会有所降低。

kafka和rabbitmq都支持事务。
kafka消息堆积：增加分区同时增加消费实例

Kafka 仅仅使用 Consumer Group 这一种机制，却同时实现了传统消息引擎系统的两大模型：

如果所有实例都属于同一个 Group，那么它实现的就是消息队列模型；
如果所有实例分别属于不同的 Group，那么它实现的就是发布 / 订阅模型。

Consumer 实例可能会被 Coordinator 错误地认为“已停止”从而被“踢出”Group，当 Consumer Group 完成 Rebalance 之后，每个 Consumer 实例都会定期地向 Coordinator 发送心跳请求，表明它还存活着。
Consumer 端有个参数，叫 session.timeout.ms，就是被用来表征此事的。该参数的默认值是 10 秒，即如果 Coordinator 在 10 秒之内没有收到 Group 下某 Consumer 实例的心跳。
heartbeat.interval.ms。这个值设置得越小，Consumer 实例发送心跳请求的频率就越高。
max.poll.interval.ms：它的默认值是 5 分钟，表示你的 Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起“离开组”的请求。
设置 session.timeout.ms = 6s。
设置 heartbeat.interval.ms = 2s。
要保证 Consumer 实例在被判定为“dead”之前，能够发送至少 3 轮的心跳请求，即 session.timeout.ms >= 3 * heartbeat.interval.ms。
最好将该参数值设置得大一点，比你的下游最大处理时间稍长一点。
对于集群中的每一个broker都保存着相同的完整的整个集群的metadata信息;
metadata信息里包括了每个topic的所有partition的信息: leader, leader_epoch, controller_epoch, isr, replicas等;
Kafka客户端从任一broker都可以获取到需要的metadata信息;


压缩：用时间换空间
缓存：用空间换时间






